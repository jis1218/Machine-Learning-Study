##### 일반적인 Spoken Dialog System
##### User Input : 보통 잡음이 섞인 음성 신호이다.
##### Automatic Speech Recognition(ASR) : 언어파형이 벡터로 변환됨, speech recognition(음성 인식)이 문자로 변환됨
##### Spoken Language Understanding(SLU) : 사용자의 발언은 NLP에 의해 분석된다. SLU는 전처리된 발언을 의미 추출기, 통계적 모델에 의해 추출된 대화법, 사용자의 목표, 명명된 개체 등으로 이루어진 의미있는 표현에 맵핑 시킨다.
##### Dialog Management(DM) : spoken dialog system의 핵심, 모든 구성 요소의 활동을 조정(?), 대화 흐름 제어, 외부 응용 프로그램과 통신한다. DM은 담화 문맥을 바탕으로 담화 분석, 지식 데이터베이스 질의, 시스템 행동 예측 등의 중요한 역할을 한다.
##### Natural Language Generation(NLG) : 외부 지식 기반 데이터베이스의 아이템(레스토랑 데이터베이스)을 사용해 사용자의 요청에 자연어로 응답해준다.
##### System Output : 화면에 응답을 띄워주거나 미리 녹음된 오디오로 대답해준다.

##### 이 중 DM이 가장 중심적인 역할을 한다. DM의 가장 큰 역할은 SLU의 결과로부터 관찰된 것과 추론된 대화 상태를 기반으로 알맞은 조치를 선택하는 것이다.

### 2. Dialog Management

#### 2.1 DM의 역할
##### DM은 SLU의 결과로 만들어진 semantic frame에 표현된 사용자의 의도를 받아들인다. 그리고 알아들을 수 있게 시스템의 응답을 출력한다. 시스템의 응답은 담화의 history을 유지하며 문맥을 반영시켜야 한다. DM의 역할은 작업의 유형에 따라 다를 수 있지만 핵심 역할은 다음과 같다.
> ##### 현재 입력된 것과 문맥을 바탕으로 외부 데이터베이스에 연결하여 쿼리 결과를 탐색하고 제공한다.
> ##### 알맞은 쿼리를 데이터베이스에 제공하기 위해 빠진 정보를 물어본다.
> ##### 사용자의 입력이 처리할 수 있는 범위 밖이면 빠진 정보를 요청한다.
> ##### NLG 및 TTS 모듈에서 시스템의 발언을 출력하기 위해 concept level(?)에서 다음 시스템 동작 예측
> ##### 좀 더 사람과 같은 대화 시스템을 위해 사람 대 사람의 대화에서 일반적인 대화 메커니즘을 controlling(?)한다. 

#### 2.2 주도권(Initiative)의 정도
##### dialog의 과정은 사용자와 시스템의 주도권이 뒤바뀌는, 정보의 교환이라 볼 수 있다. 주도권은 누가 대화의 진행을 리드하느냐이다. 보통 주도권의 정도는 다음과 같은 전략 중 하나이다.
> ##### System-initiative : 시스템이 주도권을 가지고 있다.
> ##### User-initiative : 사용자가 대화를 주도한다. 시스템은 사용자의 요구에 따라 대답한다.
> ##### Mixed-initiative : 시스템이 대화를 전반적으로 주도하나 사용자가 대화의 주도권을 가져올 수 있다.
##### System-initiative 대화에서 시스템은 하나 또는 그 이상의 질문을 사용자에게 단계적으로 함으로써 정보를 얻는다. 정보(slot)이 다 채워졌으면 시스템은 외부 데이터베이스에 적절한 쿼리를 보낼 수 있다. 이런 대화는 사용자의 입력이 한 단어 또는 구문으로 제한되게 시스템을 설계한다. 이러한 형태의 대화의 장점은 사용자의 입력을 제한된 형태로만 받을 수 있다는 것이다. 하지만 단점은 많은 정보(slot)이 필요한 복잡한 작업을 완료하는데 많은 시간이 걸린다는 것이다. 또한 단어와 구문이 제한적이므로 대화의 흐름이 정해진 형태여만 하기 때문에 사용자의 입력이 부자연스러울 수 있다.
##### User-initiative 대화는 사용자가 대화를 주도하고 시스템은 가끔 얻고자 하는 정보가 확실하지 않은 경우 확인차 질문한다. 사용자는 질문을 자유롭게 정할 수 있고 시스템은 그 질문에 응답한다. 이 방법의 장점은 사용자가 시스템과 자유롭고 자연스럽게 대화할 수 있다는 것이다. 사실 user-initiative system을 개발하는 것은 상당히 복잡하다. 왜냐하면 ASR과 SLU가 많은 양의 문법과 단어를 다뤄야 하기 때문이다. 또한 DM은 좀더 유연한 대화의 흐름을 조절해야 하기 때문이다.
##### mixed-initiative dialog는 시스템이 대화를 주도하나 사용자가 때때로 유연함을 가지고 정보를 더 제공하거나 또는 대화의 흐름을 바꿀 수 있다. 따라서 mixed-initiative system은 복잡한 turn-taking 메커니즘을 포함해야 한다. 최근 진보된 dialog system은 이 타입으로 구현하고자 시도되었는데 왜냐하면 사람과 사람의 대화처럼 보이기 떄문이다. 하지만 이 타입을 사용하기 위해서는 몇몇 문제가 해결되어야 한다. 예를들어 barge-in 발화는 그것의 경계를 탐지하기가 어렵고 또한 제대로 인식하는 것도 어렵다. (barge-in 발화는 대화 주제가 바뀌는 발화인 것 같음)

#### 2.3 오류 처리
##### ASR과 SLU의 발전에 따라 spoken dialog system은 다양한 용도로 개발될 수 있다. 그럼에도 불구하고 실제 dialog system을 사용하는데는 중요한 문제들이 있는데 그 중 하나가 ASR과 SLU 모듈로부터의 error propagation이다. 보통 spoken dialog system의 오류는 음성 인식과 언어 이해가 대부분이다. 사용자의 입력이 명확하지 않거나 완전하지 않을 경우 SLU는 정확한 의미를 잡아내지 못한다. 이런 오류는 사용자의 의도를 잘못 이해하게 하고 적절하지 않은 응답을 주게 한다. 이 오류를 피하기 위해 인식의 정확도와 견고성을 개선해야 한다. 그러나 완벽한 ASR과 SLU 모듈을 개발하는 것은 불가능한 것처럼 여겨졌는데 그 이유는 잡음과 갑작스러운 입력 때문이다.